"""æµ‹è¯• v1_naive ç‰ˆæœ¬"""

import sys
sys.path.append('..')

from core.v1_naive import InferenceEngine


def test_single_request():
    """æµ‹è¯•å•ä¸ªè¯·æ±‚"""
    print("\n" + "="*50)
    print("æµ‹è¯•1: å•ä¸ªè¯·æ±‚")
    print("="*50)
    
    engine = InferenceEngine(num_blocks=10, block_size=16, max_batch_size=1)
    engine.add_request("req1", "Hello", max_tokens=5)
    engine.run()


def test_batch_requests():
    """æµ‹è¯•æ‰¹å¤„ç†"""
    print("\n" + "="*50)
    print("æµ‹è¯•2: æ‰¹å¤„ç†è¯·æ±‚")
    print("="*50)
    
    engine = InferenceEngine(num_blocks=20, block_size=16, max_batch_size=4)
    engine.add_request("req1", "Hello", max_tokens=3)
    engine.add_request("req2", "World", max_tokens=5)
    engine.add_request("req3", "AI", max_tokens=4)
    engine.run()


def test_oom():
    """æµ‹è¯•æ˜¾å­˜ä¸è¶³çš„æƒ…å†µ"""
    print("\n" + "="*50)
    print("æµ‹è¯•3: OOM åœºæ™¯ï¼ˆv1 ä¼šå´©æºƒï¼Œè¿™æ˜¯é¢„æœŸçš„ï¼‰")
    print("="*50)
    
    # åªæœ‰2ä¸ªå—ï¼Œä½†è¦å¤„ç†å¤šä¸ªè¯·æ±‚
    engine = InferenceEngine(num_blocks=2, block_size=16, max_batch_size=4)
    engine.add_request("req1", "Hello", max_tokens=3)
    engine.add_request("req2", "World", max_tokens=3)
    engine.add_request("req3", "AI", max_tokens=3)  # è¿™ä¸ªä¼š OOM
    engine.run()


if __name__ == "__main__":
    test_single_request()
    test_batch_requests()
    
    print("\n" + "="*50)
    print("âš ï¸  æ¥ä¸‹æ¥ä¼šæµ‹è¯• OOMï¼ˆé¢„æœŸä¼šå¤±è´¥ï¼‰")
    print("="*50)
    try:
        test_oom()
    except RuntimeError as e:
        print(f"\nâœ“ é¢„æœŸçš„ OOM é”™è¯¯: {e}")
    
    print("\n" + "="*50)
    print("âœ… v1_naive æµ‹è¯•å®Œæˆ")
    print("ğŸ’¡ å‡çº§åˆ° v2_lru æ¥ä¼˜é›…å¤„ç† OOMï¼ˆä½¿ç”¨ LRU evictionï¼‰")
    print("="*50)

