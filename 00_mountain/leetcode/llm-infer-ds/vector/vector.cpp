// ==============================================================================
// Vector / Dynamic Array - 对应 LLM Inference 中的 KV Cache, Tensor
// ==============================================================================
//
// 【对应引擎模块】
//   - KV Cache: 存储每个 token 的 key/value 向量
//   - Tensor: 多维数组的底层存储
//
// 【学习重点】
//   1. 连续内存布局：所有元素在内存中连续存储，cache-friendly
//   2. 扩容机制：当容量不足时如何进行 2x 扩容（malloc -> memcpy -> free）
//   3. Stride (步长) 访问：模拟 Tensor 的多维访问模式
//
// 【实现要求】
//   - 实现 push_back, pop_back, operator[], resize 等核心操作
//   - 支持 stride 访问：给定起始位置和步长，返回指定元素
//   - 测试扩容时的性能和内存拷贝开销
//
// 【练习目标】
//   - 深入理解连续内存的优势（SIMD、预取）
//   - 掌握动态扩容的 amortized O(1) 复杂度分析
//   - 模拟 vLLM 中 KV Cache 的内存管理
// ==============================================================================
