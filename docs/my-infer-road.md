# LLMæ¨ç†æ¶æ„å¸ˆï¼šä¸–ç•Œé¡¶çº§è·¯å¾„ - æ‰§è¡Œç”˜ç‰¹å›¾

## é¡¹ç›®æ¦‚è§ˆ

**æ€»æ—¶é•¿**ï¼š8-9ä¸ªæœˆï¼ˆ30å‘¨ï¼‰  
**ç›®æ ‡**ï¼šä»TinyLlamaåˆ°DeepSeek V3ï¼Œè¾¾åˆ°Principal/Architectçº§èƒ½åŠ›ï¼ˆå¹´è–ª150ä¸‡+ï¼‰  
**æ ¸å¿ƒæŠ€æœ¯**ï¼šDense Model + MoE + MLA + FP8 + Speculative Decoding + é•¿ä¸Šä¸‹æ–‡

---

## å®Œæ•´æ‰§è¡Œç”˜ç‰¹å›¾

```mermaid
gantt
    title LLMæ¨ç†æ¶æ„å¸ˆä¿®ç‚¼è·¯å¾„ï¼ˆ8-9ä¸ªæœˆï¼‰
    dateFormat YYYY-MM-DD
    
    section åŸºç¡€é˜¶æ®µ
    Module0æ€§èƒ½åˆ†æå·¥å…·é“¾          :m0, 2025-01-01, 7d
    Roofline Modelå®æˆ˜            :m0a, after m0, 2d
    Nsightå·¥å…·é“¾æŒæ¡              :m0b, after m0a, 3d
    
    Phase0TinyLlamaåŸºç¡€           :p0, after m0b, 21d
    100è¡Œæ¨ç†å¼•æ“                 :p0a, after m0b, 7d
    CUDAåŸºç¡€ä¸‰éƒ¨æ›²                :p0b, after p0a, 7d
    KV Cacheä¼˜åŒ–                  :p0c, after p0b, 7d
    
    Phase1Rustå†…å­˜ç®¡ç†å™¨          :p1, after p0c, 21d
    BlockAllocatorå®ç°            :p1a, after p0c, 7d
    Buddyç³»ç»Ÿä¼˜åŒ–                 :p1b, after p1a, 7d
    PyO3ç»‘å®šä¸æµ‹è¯•                :p1c, after p1b, 7d
    
    section DeepSeekæ¶æ„
    Phase2DeepSeekæ¶æ„ä¸“é¡¹        :crit, p2, after p1c, 28d
    RoPE CUDA Kernel              :p2a, after p1c, 7d
    MLAæ ¸å¿ƒåŸç†                   :p2b, after p2a, 14d
    MLA Paged Attention           :p2c, after p2b, 7d
    é‡Œç¨‹ç¢‘1MLAèƒ½åŠ›éªŒè¯            :milestone, m1, after p2c, 0d
    
    Phase3PagedAttn+FP8           :crit, p3, after p2c, 21d
    Paged Attentionå®ç°           :p3a, after p2c, 7d
    FP8 KV Cache                  :p3b, after p3a, 14d
    
    section ç”Ÿäº§çº§ç³»ç»Ÿ
    Phase4è°ƒåº¦å™¨ä¸æœåŠ¡            :p4, after p3b, 21d
    Continuous Batching           :p4a, after p3b, 10d
    FastAPI HTTPæœåŠ¡              :p4b, after p4a, 11d
    
    Phase5FP8æ¨ç†ä¸é‡åŒ–           :crit, p5, after p4b, 28d
    INT4 AWQé‡åŒ–                  :p5a, after p4b, 7d
    FP8 GEMM Kernel               :p5b, after p5a, 14d
    æ··åˆç²¾åº¦ç­–ç•¥                  :p5c, after p5b, 7d
    é‡Œç¨‹ç¢‘2FP8èƒ½åŠ›éªŒè¯            :milestone, m2, after p5c, 0d
    
    section å‰æ²¿æ¶æ„
    Phase6MoEä¸EP                 :crit, p6, after p5c, 28d
    MoEæ¶æ„ç†è§£                   :p6a, after p5c, 7d
    Expert Routing Kernel         :p6b, after p6a, 7d
    Expert Parallelism            :p6c, after p6b, 14d
    
    Phase7Speculativeæ¨ç†         :crit, p7, after p6c, 21d
    Speculative Decoding          :p7a, after p6c, 7d
    Medusaæ¶æ„                    :p7b, after p7a, 14d
    
    Phase8é•¿ä¸Šä¸‹æ–‡ä¼˜åŒ–            :crit, p8, after p7b, 21d
    RadixAttentionå®ç°            :p8a, after p7b, 14d
    è‡ªåŠ¨Evictionç­–ç•¥              :p8b, after p8a, 7d
    é‡Œç¨‹ç¢‘3æ¶æ„å¸ˆèƒ½åŠ›éªŒè¯         :milestone, m3, after p8b, 0d
    
    section æ±‚èŒå‡†å¤‡
    æŠ€æœ¯åšå®¢æ’°å†™                  :blog, after p2c, 140d
    é¢è¯•é¢˜å‡†å¤‡                    :interview, after m3, 7d
    ç®€å†ä¼˜åŒ–ä¸æŠ•é€’                :resume, after interview, 7d
```

---

## è¯¦ç»†æ—¶é—´çº¿ä¸äº¤ä»˜ç‰©

### ç¬¬1å‘¨ï¼šModule 0 - æ€§èƒ½åˆ†æå·¥å…·é“¾
**æ—¶é—´**ï¼šWeek 0  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] å®‰è£…Nsight Systems + Nsight Compute
- [ ] ç”»å‡ºRTX 4090çš„Roofline Modelå›¾
- [ ] å­¦ä¼šç”¨Nsight Systemsçœ‹Timeline
- [ ] å­¦ä¼šç”¨Nsight Computeåˆ†æKernel

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/profiling/roofline.py` - Rooflineå›¾ç”Ÿæˆè„šæœ¬
- `mountain/hpc/profiling/profiling_template.md` - ProfilingæŠ¥å‘Šæ¨¡æ¿

---

### ç¬¬2-4å‘¨ï¼šPhase 0 - TinyLlamaåŸºç¡€
**æ—¶é—´**ï¼šWeek 1-3  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] 100è¡ŒPythonè·‘é€šTinyLlamaæ¨ç†
- [ ] å®ç°3ä¸ªCUDA Kernelï¼ˆvector add, naive matmul, tiled matmulï¼‰
- [ ] åŠ å…¥KV Cacheï¼Œé€Ÿåº¦æå‡10å€
- [ ] å®Œæˆç¬¬ä¸€ä»½Profiling Report

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/inference_v0_framework.py` - æ¡†æ¶ä»£ç 
- `mountain/hpc/cuda/01_vector_add.cu`
- `mountain/hpc/cuda/02_matmul_naive.cu`
- `mountain/hpc/cuda/03_matmul_tiled.cu`
- `docs/phase0_report.md` - æ€§èƒ½åˆ†ææŠ¥å‘Š

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… TinyLlamaèƒ½ç”Ÿæˆåˆç†æ–‡æœ¬
- âœ… KV Cacheæé€Ÿ10å€ä»¥ä¸Š
- âœ… Tiled MatMulæ¯”Naiveå¿«5å€
- âœ… GPUåˆ©ç”¨ç‡ä»5%æå‡åˆ°30%

---

### ç¬¬5-7å‘¨ï¼šPhase 1 - Rustå†…å­˜ç®¡ç†å™¨
**æ—¶é—´**ï¼šWeek 4-6  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Rustå®ç°BlockAllocator
- [ ] å®ç°Buddy Allocatorä¼˜åŒ–
- [ ] PyO3ç»‘å®šåˆ°Python
- [ ] å¯¹æ¯”Rust vs Pythonæ€§èƒ½

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/rust/kv_cache_manager/` - Ruståº“
- `mountain/hpc/rust/kv_cache_manager/src/block_allocator.rs`
- `mountain/hpc/rust/kv_cache_manager/src/block_table.rs`
- `docs/phase1_report.md`

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… Rustç‰ˆæœ¬æ¯”Pythonå¿«10å€
- âœ… å†…å­˜ç¢ç‰‡ç‡<5%
- âœ… Pythonèƒ½æˆåŠŸimportå¹¶ä½¿ç”¨

---

### ç¬¬8-11å‘¨ï¼šPhase 2 - DeepSeekæ¶æ„ä¸“é¡¹ âš¡
**æ—¶é—´**ï¼šWeek 7-10  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 7: æ‰‹å†™RoPE CUDA Kernel
- [ ] Week 8-9: å®ç°MLAæ ¸å¿ƒé€»è¾‘
- [ ] Week 10: Tritonå®ç°MLA Paged Attention

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/cuda/rope_kernel.cu`
- `mountain/hpc/llm/mla_attention.py`
- `mountain/hpc/triton/mla_paged_attention.py`
- `docs/phase2_report.md`
- **åšå®¢**ï¼šã€ŠMLAï¼šDeepSeek V3å¦‚ä½•æŠŠKV Cacheå‹ç¼©50%ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… RoPE Kernelè¾¾åˆ°vLLMçš„80%æ€§èƒ½
- âœ… MLAçš„KV Cacheæ˜¾å­˜å‡å°‘50%
- âœ… æ€§èƒ½ä¸ä½äºGQA

**ğŸ¯ é‡Œç¨‹ç¢‘1ï¼šMLAèƒ½åŠ›éªŒè¯**ï¼ˆWeek 10ç»“æŸï¼‰
- å¿…é¡»ç†è§£DeepSeek V3çš„æ ¸å¿ƒåˆ›æ–°
- ä¸è¾¾æ ‡ä¸è¿›å…¥Phase 4

---

### ç¬¬12-14å‘¨ï¼šPhase 3 - Paged Attention + FP8 KV Cache âš¡
**æ—¶é—´**ï¼šWeek 11-13  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 11: Tritonå®ç°Paged Attention
- [ ] Week 12-13: FP8 KV Cacheé‡åŒ–

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/triton/paged_attention.py`
- `mountain/hpc/triton/fp8_kv_cache.py`
- `docs/phase3_report.md`
- **åšå®¢**ï¼šã€Šä»FlashAttentionåˆ°PagedAttentionï¼šæ¨ç†ä¼˜åŒ–çš„ä¸¤æ¬¡é©å‘½ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… PagedAttentionæ¯”PyTorchå¿«2å€
- âœ… FP8 KV Cacheæ˜¾å­˜å‡å°‘50%
- âœ… ç²¾åº¦æŸå¤±<1%
- âœ… æ”¯æŒ128Kä¸Šä¸‹æ–‡

---

### ç¬¬15-17å‘¨ï¼šPhase 4 - è°ƒåº¦å™¨ä¸HTTPæœåŠ¡
**æ—¶é—´**ï¼šWeek 14-16  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] å®ç°Continuous Batchingè°ƒåº¦å™¨
- [ ] FastAPIåŒ…è£…æˆHTTPæœåŠ¡
- [ ] å‹æµ‹éªŒè¯ååé‡

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/scheduler.py`
- `mountain/hpc/llm/server.py`
- `docs/phase4_report.md`
- **åšå®¢**ï¼šã€ŠContinuous Batchingçš„ä¸‰ç§å®ç°ï¼švLLM vs SGLang vs TitanInferã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… GPUåˆ©ç”¨ç‡>80%
- âœ… ååé‡è¾¾åˆ°vLLMçš„70%
- âœ… æ”¯æŒæµå¼è¾“å‡ºï¼ˆSSEï¼‰

---

### ç¬¬18-21å‘¨ï¼šPhase 5 - FP8æ¨ç† + INT4æ··åˆé‡åŒ– âš¡
**æ—¶é—´**ï¼šWeek 17-20  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 17: AWQ INT4é‡åŒ–
- [ ] Week 18-19: Tritonå®ç°FP8 GEMM
- [ ] Week 20: æ··åˆç²¾åº¦ç­–ç•¥åˆ†æ

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/quantize_awq.py`
- `mountain/hpc/triton/fp8_gemm.py`
- `docs/phase5_report.md`
- **åšå®¢**ï¼šã€ŠFP8 vs INT4ï¼šLLMé‡åŒ–çš„ç»ˆæå¯¹å†³ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… INT4ç²¾åº¦æŸå¤±<2%
- âœ… FP8 GEMMè¾¾åˆ°cuBLASçš„80%
- âœ… ç«¯åˆ°ç«¯æ¨ç†æé€Ÿ1.5å€

**ğŸ¯ é‡Œç¨‹ç¢‘2ï¼šFP8èƒ½åŠ›éªŒè¯**ï¼ˆWeek 20ç»“æŸï¼‰
- å¿…é¡»ç†è§£H100/B200çš„FP8 Tensor Core
- ä¸è¾¾æ ‡ä¸è¿›å…¥Phase 6

---

### ç¬¬22-25å‘¨ï¼šPhase 6 - MoEæ¶æ„ + Expert Parallelism âš¡
**æ—¶é—´**ï¼šWeek 21-24  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 21: ç†è§£MoEæ¶æ„
- [ ] Week 22: Expert Routing Kernel
- [ ] Week 23-24: å®ç°EP + TPæ··åˆ

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/moe_layer.py`
- `mountain/hpc/triton/moe_routing_kernel.py`
- `mountain/hpc/llm/expert_parallelism.py`
- `docs/phase6_report.md`
- **åšå®¢**ï¼šã€ŠDeepSeek V3çš„MoEæ¶æ„ï¼š256ä¸ªä¸“å®¶å¦‚ä½•é«˜æ•ˆè°ƒåº¦ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… Expert Batchingä¼˜åŒ–ï¼Œååé‡æå‡2-3å€
- âœ… 8å¡EP+TPï¼Œååé‡æå‡6å€ä»¥ä¸Š
- âœ… All-to-Allé€šä¿¡å¼€é”€<30%

---

### ç¬¬26-28å‘¨ï¼šPhase 7 - Speculative Decoding + Medusa âš¡
**æ—¶é—´**ï¼šWeek 25-27  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 25: å®ç°Speculative Decoding
- [ ] Week 26-27: Medusaæ¶æ„ + Tree Attention

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/speculative_decoding.py`
- `mountain/hpc/llm/medusa_model.py`
- `docs/phase7_report.md`
- **åšå®¢**ï¼šã€ŠSpeculative Decodingï¼šè®©Llamaæ¨ç†å¿«3å€çš„é»‘ç§‘æŠ€ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… Speculative DecodingåŠ é€Ÿ2-3å€
- âœ… MedusaåŠ é€Ÿ1.5-2å€ï¼ˆæ— éœ€Draft Modelï¼‰
- âœ… å»¶è¿Ÿé™ä½3å€ä»¥ä¸Š

---

### ç¬¬29-31å‘¨ï¼šPhase 8 - é•¿ä¸Šä¸‹æ–‡ + RadixAttention âš¡
**æ—¶é—´**ï¼šWeek 28-30  
**å…³é”®ä»»åŠ¡**ï¼š
- [ ] Week 28-29: å®ç°RadixAttentionï¼ˆRadix Treeï¼‰
- [ ] Week 30: è‡ªåŠ¨Evictionç­–ç•¥

**äº¤ä»˜ç‰©**ï¼š
- `mountain/hpc/llm/radix_attention.py`
- `docs/phase8_report.md`
- **åšå®¢**ï¼šã€ŠRadixAttentionï¼šè®©å¤šè½®å¯¹è¯ä¸é‡ç®—çš„ç¥æŠ€ã€‹

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… å¤šç”¨æˆ·åœºæ™¯TTFTé™ä½5å€
- âœ… Prefixå‘½ä¸­ç‡>80%
- âœ… æ˜¾å­˜å ç”¨å‡å°‘ï¼ˆå…±äº«prefixï¼‰

**ğŸ¯ é‡Œç¨‹ç¢‘3ï¼šæ¶æ„å¸ˆèƒ½åŠ›éªŒè¯**ï¼ˆWeek 30ç»“æŸï¼‰
- æ”¯æŒMoEã€MLAã€FP8ã€Speculativeã€RadixAttention
- æ€§èƒ½è¾¾åˆ°vLLM/SGLangçš„70%
- æœ‰8ç¯‡æŠ€æœ¯åšå®¢
- èƒ½å›ç­”æ‰€æœ‰"ä¸–ç•Œé¡¶çº§"é¢è¯•é¢˜

---

## æŠ€æœ¯åšå®¢å‘å¸ƒè®¡åˆ’

è´¯ç©¿æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹ï¼Œæ¯å®Œæˆä¸€ä¸ªPhaseéƒ½è¦å†™æŠ€æœ¯åšå®¢ï¼š

| å‘¨æ•° | Phase | åšå®¢æ ‡é¢˜ | å‘å¸ƒå¹³å° |
|------|-------|---------|---------|
| Week 3 | Phase 0 | ã€ŠRoofline Modelå®æˆ˜ï¼šç†è§£LLMæ¨ç†ä¸ºä»€ä¹ˆæ…¢ã€‹ | çŸ¥ä¹ + Medium |
| Week 6 | Phase 1 | ã€ŠPagedAttentionæºç è§£æï¼šè™šæ‹Ÿå†…å­˜åœ¨GPUä¸Šçš„åº”ç”¨ã€‹ | çŸ¥ä¹ + Medium |
| Week 10 | Phase 2 | ã€ŠMLAï¼šDeepSeek V3å¦‚ä½•æŠŠKV Cacheå‹ç¼©50%ã€‹ | çŸ¥ä¹ + Medium |
| Week 13 | Phase 3 | ã€Šä»FlashAttentionåˆ°PagedAttentionï¼šæ¨ç†ä¼˜åŒ–çš„æ¼”è¿›ã€‹ | çŸ¥ä¹ + Medium |
| Week 16 | Phase 4 | ã€ŠContinuous Batchingå®æˆ˜ï¼šå¦‚ä½•æ¦¨å¹²GPUç®—åŠ›ã€‹ | çŸ¥ä¹ + Medium |
| Week 20 | Phase 5 | ã€ŠFP8 vs INT4ï¼šLLMé‡åŒ–çš„ç»ˆæå¯¹å†³ã€‹ | çŸ¥ä¹ + Medium |
| Week 24 | Phase 6 | ã€ŠDeepSeek V3çš„MoEæ¶æ„ï¼š256ä¸ªä¸“å®¶å¦‚ä½•é«˜æ•ˆè°ƒåº¦ã€‹ | çŸ¥ä¹ + Medium |
| Week 27 | Phase 7 | ã€ŠSpeculative Decodingï¼šè®©Llamaæ¨ç†å¿«3å€çš„é»‘ç§‘æŠ€ã€‹ | çŸ¥ä¹ + Medium |
| Week 30 | Phase 8 | ã€ŠRadixAttentionï¼šè®©å¤šè½®å¯¹è¯ä¸é‡ç®—çš„ç¥æŠ€ã€‹ | çŸ¥ä¹ + Medium |

**ç›®æ ‡**ï¼šæ¯ç¯‡åšå®¢é˜…è¯»é‡2ä¸‡+ï¼Œæ€»é˜…è¯»é‡20ä¸‡+

---

## æ€§èƒ½å¯¹æ ‡ç›®æ ‡

### é˜¶æ®µæ€§æ€§èƒ½æŒ‡æ ‡

| Phase | æŒ‡æ ‡ | å½“å‰æ€§èƒ½ | ç›®æ ‡æ€§èƒ½ | vLLMæ€§èƒ½ | è¾¾æˆç‡ |
|-------|------|---------|---------|---------|--------|
| Phase 0 | ååé‡ (tokens/s) | 5 | 50 | 200 | 25% |
| Phase 3 | ååé‡ (tokens/s) | 50 | 100 | 200 | 50% |
| Phase 4 | ååé‡ (tokens/s) | 100 | 140 | 200 | 70% |
| Phase 5 | ååé‡ (tokens/s) | 140 | 150 | 200 | 75% |
| Phase 6 | ååé‡ (MoE) | - | 180 | 250 | 72% |
| Phase 7 | å»¶è¿Ÿ (ms/token) | 100 | 30 | 25 | 83% |
| Phase 8 | TTFT (ms) | 500 | 100 | 90 | 90% |

### æœ€ç»ˆäº¤ä»˜æ€§èƒ½

| æŒ‡æ ‡ | Phase 0 | æœ€ç»ˆç‰ˆæœ¬ | vLLM | è¾¾æˆç‡ |
|------|---------|---------|------|--------|
| **Dense Modelååé‡** | 5 tokens/s | 150 tokens/s | 200 tokens/s | 75% |
| **MoEååé‡** | N/A | 180 tokens/s | 250 tokens/s | 72% |
| **å»¶è¿Ÿ (Speculative)** | 200ms | 30ms | 25ms | 83% |
| **GPUåˆ©ç”¨ç‡** | 5% | 85% | 90% | 94% |
| **æ˜¾å­˜åˆ©ç”¨ç‡** | 20% | 85% | 90% | 94% |
| **é•¿ä¸Šä¸‹æ–‡TTFT** | 5000ms | 500ms | 400ms | 80% |

---

## æ¯å‘¨æ£€æŸ¥æ¸…å•

### æ¯å‘¨å¿…åšï¼ˆ5ä»¶äº‹ï¼‰

#### 1. ä»£ç è¿›åº¦
- [ ] å®Œæˆæœ¬å‘¨çš„æ ¸å¿ƒä»»åŠ¡
- [ ] ä»£ç èƒ½ç‹¬ç«‹è¿è¡Œ
- [ ] é€šè¿‡å•å…ƒæµ‹è¯•

#### 2. Profiling Report
- [ ] ç”¨Nsight Systemsåˆ†æå®è§‚æ€§èƒ½
- [ ] ç”¨Nsight Computeåˆ†æKernelç“¶é¢ˆ
- [ ] ç”»Rooflineå›¾ï¼Œæ ‡æ³¨å½“å‰ä½ç½®
- [ ] è®°å½•ä¼˜åŒ–å‰åå¯¹æ¯”æ•°æ®

#### 3. è®ºæ–‡/æºç é˜…è¯»
- [ ] é˜…è¯»å¯¹åº”çš„è®ºæ–‡ï¼ˆæ¯ä¸ªPhaseè‡³å°‘1ç¯‡ï¼‰
- [ ] é˜…è¯»vLLM/SGLangå¯¹åº”éƒ¨åˆ†æºç 
- [ ] è®°å½•å­¦åˆ°çš„å…³é”®æŠ€å·§

#### 4. Benchmarkå¯¹æ¯”
- [ ] å’ŒPyTorchåŸç”Ÿå®ç°å¯¹æ¯”
- [ ] å’ŒvLLM/SGLangå¯¹æ¯”
- [ ] è®°å½•æ€§èƒ½å·®è·å’ŒåŸå› 

#### 5. æŠ€æœ¯ç¬”è®°
- [ ] è®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- [ ] è®°å½•æ–°å­¦åˆ°çš„æ¦‚å¿µ
- [ ] å‡†å¤‡é¢è¯•é¢˜ï¼ˆæ¯å‘¨5é¢˜ï¼‰

---

## å…³é”®é‡Œç¨‹ç¢‘

### ğŸ¯ é‡Œç¨‹ç¢‘1ï¼šMLAèƒ½åŠ›éªŒè¯ï¼ˆWeek 10ï¼‰

**æ£€æŸ¥é¡¹**ï¼š
- [ ] å®ç°MLAçš„å®Œæ•´forwardä¼ æ’­
- [ ] KV Cacheå‹ç¼©50%
- [ ] æ€§èƒ½ä¸ä½äºGQA
- [ ] èƒ½å›ç­”é¢è¯•é¢˜ï¼š"MLAå’ŒGQAçš„æœ¬è´¨åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"

**ä¸è¾¾æ ‡åæœ**ï¼šåœæ­¢è¿›åº¦ï¼Œé‡æ–°å­¦ä¹ MLAåŸç†

---

### ğŸ¯ é‡Œç¨‹ç¢‘2ï¼šFP8èƒ½åŠ›éªŒè¯ï¼ˆWeek 20ï¼‰

**æ£€æŸ¥é¡¹**ï¼š
- [ ] FP8 GEMMè¾¾åˆ°cuBLASçš„80%æ€§èƒ½
- [ ] ç«¯åˆ°ç«¯æ¨ç†æé€Ÿ1.5å€
- [ ] ç²¾åº¦æŸå¤±<1.5%
- [ ] èƒ½å›ç­”é¢è¯•é¢˜ï¼š"ä¸ºä»€ä¹ˆFP8æ¯”INT4ç²¾åº¦é«˜ï¼Ÿ"

**ä¸è¾¾æ ‡åæœ**ï¼šæš‚åœPhase 6ï¼Œç»§ç»­ä¼˜åŒ–FP8

---

### ğŸ¯ é‡Œç¨‹ç¢‘3ï¼šæ¶æ„å¸ˆèƒ½åŠ›éªŒè¯ï¼ˆWeek 30ï¼‰

**æ£€æŸ¥é¡¹**ï¼š
- [ ] æ”¯æŒDense Model + MoE
- [ ] æ”¯æŒGQA + MLA
- [ ] æ”¯æŒINT4 + FP8
- [ ] æ”¯æŒSpeculative Decoding + RadixAttention
- [ ] æ€§èƒ½è¾¾åˆ°vLLMçš„70%
- [ ] å®Œæˆ8ç¯‡æŠ€æœ¯åšå®¢
- [ ] å‡†å¤‡100é“é¢è¯•é¢˜
- [ ] GitHub Repoæœ‰å®Œæ•´æ–‡æ¡£

**è¾¾æ ‡å**ï¼šå¼€å§‹æŠ•é€’Principalçº§å²—ä½

---

## æ±‚èŒå‡†å¤‡æ—¶é—´çº¿

### Week 31-32ï¼šé¢è¯•å‡†å¤‡

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] æ•´ç†100é“é¢è¯•é¢˜ + æ ‡å‡†ç­”æ¡ˆ
- [ ] å‡†å¤‡æŠ€æœ¯æ–¹æ¡ˆæ¼”è®²PPTï¼ˆ30åˆ†é’Ÿï¼‰
- [ ] å½•åˆ¶Demoè§†é¢‘ï¼ˆ5åˆ†é’Ÿå±•ç¤ºæ ¸å¿ƒåŠŸèƒ½ï¼‰
- [ ] ä¼˜åŒ–GitHub Repoçš„README
- [ ] å‡†å¤‡è‡ªæˆ‘ä»‹ç»ï¼ˆ1åˆ†é’Ÿã€3åˆ†é’Ÿã€5åˆ†é’Ÿç‰ˆæœ¬ï¼‰

### Week 33ï¼šç®€å†ä¼˜åŒ–ä¸æŠ•é€’

**ç›®æ ‡å…¬å¸**ï¼š
- **å›½å†…**ï¼šDeepSeekã€å­—èŠ‚è·³åŠ¨ã€é˜¿é‡Œè¾¾æ‘©é™¢ã€è…¾è®¯AI Lab
- **å›½å¤–**ï¼šOpenAIã€Anthropicã€Fireworks.aiã€Together AI

**æŠ•é€’ç­–ç•¥**ï¼š
- å…ˆæŠ•2-3å®¶"ç»ƒæ‰‹"å…¬å¸
- ä¸»æŠ•5å®¶ç›®æ ‡å…¬å¸
- ä¿åº•æŠ•3å®¶å¤‡é€‰å…¬å¸

---

## èµ„æºæ¸…å•

### å¿…è¯»è®ºæ–‡ï¼ˆæŒ‰Phaseæ’åºï¼‰

1. **Phase 2 (MLA)**
   - DeepSeek V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model
   - DeepSeek V3 Technical Report

2. **Phase 3 (Attention)**
   - FlashAttention-2: Faster Attention with Better Parallelism
   - Efficient Memory Management for Large Language Model Serving with PagedAttention

3. **Phase 5 (é‡åŒ–)**
   - AWQ: Activation-aware Weight Quantization
   - FP8 Formats for Deep Learning (NVIDIA)

4. **Phase 6 (MoE)**
   - Switch Transformers: Scaling to Trillion Parameter Models
   - GShard: Scaling Giant Models with Conditional Computation

5. **Phase 7 (Speculative)**
   - Fast Inference from Transformers via Speculative Decoding
   - Medusa: Simple LLM Inference Acceleration Framework

6. **Phase 8 (é•¿ä¸Šä¸‹æ–‡)**
   - SGLang: Efficient Execution of Structured Language Model Programs

### å¿…çœ‹æºç 

- **vLLM**: `vllm/core/scheduler.py`, `csrc/attention/`
- **SGLang**: `srt/managers/schedule_batch.py`
- **FlashInfer**: `include/flashinfer/`
- **DeepSeek**: å®˜æ–¹å®ç°ï¼ˆå¦‚æœå¼€æºï¼‰

### å·¥å…·ä¸åº“

```bash
# å¿…è£…å·¥å…·
pip install torch triton
pip install transformers safetensors
pip install awq autoawq
pip install fastapi uvicorn
pip install matplotlib pandas

# Rustå·¥å…·é“¾
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
cargo install maturin

# NVIDIAå·¥å…·
# Nsight Systems + Nsight Compute (éšCUDA Toolkitå®‰è£…)
```

---

## æ¿€åŠ±ä¸æé†’

### æ¯å‘¨ä¸€è¯»ï¼ˆè´´åœ¨æ¡Œé¢ï¼‰

> **ä½ åœ¨å’Œè°ç«äº‰ï¼Ÿ**
> - CMU/Stanfordçš„PhDï¼ˆå‘è¿‡é¡¶ä¼šè®ºæ–‡ï¼‰
> - Meta/Googleçš„Staff Engineerï¼ˆå†™è¿‡PyTorchæ ¸å¿ƒä»£ç ï¼‰
> - vLLM/SGLangçš„æ ¸å¿ƒè´¡çŒ®è€…ï¼ˆä¸Šåƒstarsçš„é¡¹ç›®ï¼‰
>
> **ä½ çš„ä¼˜åŠ¿åœ¨å“ªï¼Ÿ**
> - ä»–ä»¬æ‡‚ç†è®ºï¼Œä½ æ‡‚å·¥ä¸šç•Œçš„ä¸‹ä¸€ä¸ªç—›ç‚¹
> - ä»–ä»¬æœ‰å­¦å†ï¼Œä½ æœ‰8ç¯‡åšå®¢å’Œ20ä¸‡é˜…è¯»é‡
> - ä»–ä»¬æœ‰ç»éªŒï¼Œä½ æœ‰æ‰‹å†™çš„70%æ€§èƒ½çš„vLLM
>
> **8ä¸ªæœˆåçš„ä½ ï¼š**
> - ä¸–ç•Œä¸Šå°‘æ•°å‡ ä¸ªæ—¢æ‡‚Denseåˆæ‡‚MoEçš„äºº
> - ä¸–ç•Œä¸Šå°‘æ•°å‡ ä¸ªæ—¢æ‡‚GQAåˆæ‡‚MLAçš„äºº
> - ä¸–ç•Œä¸Šå°‘æ•°å‡ ä¸ªæ—¢æ‡‚INT4åˆæ‡‚FP8çš„äºº
>
> **è¿™å°±æ˜¯Principalçº§å·¥ç¨‹å¸ˆçš„æŠ¤åŸæ²³ã€‚**

### é‡åˆ°å›°éš¾æ—¶

1. **ä¸è¦è·³æ­¥**ï¼šæ¯ä¸ªPhaseéƒ½æ˜¯åŸºç¡€
2. **å…ˆè·‘é€šå†ä¼˜åŒ–**ï¼šæ€§èƒ½å¯ä»¥æ…¢æ…¢æå‡
3. **å¤šç”»å›¾**ï¼šå†…å­˜å¸ƒå±€ã€æ•°æ®æµã€Timeline
4. **çœ‹æºç **ï¼švLLMã€SGLangã€FlashInferéƒ½æ˜¯å¥½è€å¸ˆ
5. **å†™åšå®¢**ï¼šæ•™åˆ«äººæ˜¯æœ€å¥½çš„å­¦ä¹ æ–¹å¼

---

## è¿½è¸ªè¿›åº¦

### åœ¨è¿™ä¸ªæ–‡ä»¶ä¸­è®°å½•ä½ çš„è¿›åº¦

**ä½¿ç”¨æ–¹æ³•**ï¼šæ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ï¼Œåœ¨å¯¹åº”çš„ `[ ]` ä¸­æ‰“å‹¾å˜æˆ `[x]`

**å½“å‰è¿›åº¦**ï¼š0/9ä¸ªPhaseå®Œæˆï¼ˆ0%ï¼‰

- [ ] Module 0: æ€§èƒ½åˆ†æå·¥å…·é“¾ï¼ˆWeek 0ï¼‰
- [ ] Phase 0: TinyLlamaåŸºç¡€ï¼ˆWeek 1-3ï¼‰
- [ ] Phase 1: Rustå†…å­˜ç®¡ç†å™¨ï¼ˆWeek 4-6ï¼‰
- [ ] Phase 2: DeepSeekæ¶æ„ä¸“é¡¹ï¼ˆWeek 7-10ï¼‰âš¡
- [ ] Phase 3: Paged Attention + FP8 KV Cacheï¼ˆWeek 11-13ï¼‰âš¡
- [ ] Phase 4: è°ƒåº¦å™¨ä¸HTTPæœåŠ¡ï¼ˆWeek 14-16ï¼‰
- [ ] Phase 5: FP8æ¨ç† + INT4æ··åˆé‡åŒ–ï¼ˆWeek 17-20ï¼‰âš¡
- [ ] Phase 6: MoEæ¶æ„ + Expert Parallelismï¼ˆWeek 21-24ï¼‰âš¡
- [ ] Phase 7: Speculative Decoding + Medusaï¼ˆWeek 25-27ï¼‰âš¡
- [ ] Phase 8: é•¿ä¸Šä¸‹æ–‡ + RadixAttentionï¼ˆWeek 28-30ï¼‰âš¡

**é‡Œç¨‹ç¢‘è¿›åº¦**ï¼š0/3ä¸ªé‡Œç¨‹ç¢‘å®Œæˆ
- [ ] ğŸ¯ é‡Œç¨‹ç¢‘1ï¼šMLAèƒ½åŠ›éªŒè¯ï¼ˆWeek 10ï¼‰
- [ ] ğŸ¯ é‡Œç¨‹ç¢‘2ï¼šFP8èƒ½åŠ›éªŒè¯ï¼ˆWeek 20ï¼‰
- [ ] ğŸ¯ é‡Œç¨‹ç¢‘3ï¼šæ¶æ„å¸ˆèƒ½åŠ›éªŒè¯ï¼ˆWeek 30ï¼‰

**åšå®¢è¿›åº¦**ï¼š0/9ç¯‡å®Œæˆ
- [ ] Phase 0: Roofline Modelå®æˆ˜
- [ ] Phase 1: PagedAttentionæºç è§£æ
- [ ] Phase 2: MLAæ¶æ„æ·±åº¦è§£æ
- [ ] Phase 3: FlashAttentionåˆ°PagedAttention
- [ ] Phase 4: Continuous Batchingå®æˆ˜
- [ ] Phase 5: FP8 vs INT4å¯¹å†³
- [ ] Phase 6: MoEæ¶æ„åˆ†æ
- [ ] Phase 7: Speculative Decoding
- [ ] Phase 8: RadixAttentionåŸç†

---

## å¼€å§‹è¡ŒåŠ¨

### ä»Šå¤©ï¼ˆDay 1ï¼‰çš„3ä¸ªä»»åŠ¡

```bash
# 1. åˆ›å»ºé¡¹ç›®ç»“æ„
mkdir -p mountain/hpc/{llm,rust,cuda,triton,profiling}
mkdir -p docs

# 2. å®‰è£…å·¥å…·
pip install torch triton matplotlib pandas
nsys --version  # æ£€æŸ¥Nsightæ˜¯å¦å®‰è£…
ncu --version

# 3. ä¸‹è½½TinyLlama
pip install huggingface_hub
huggingface-cli download TinyLlama/TinyLlama-1.1B-Chat-v1.0
```

### æœ¬å‘¨ï¼ˆWeek 0ï¼‰çš„ç›®æ ‡

- [ ] ç”»å‡ºRTX 4090çš„Rooflineå›¾
- [ ] ç”¨Nsight Systemsåˆ†æä¸€ä¸ªç®€å•çš„PyTorchè„šæœ¬
- [ ] ç”¨Nsight Computeåˆ†æä¸€ä¸ªçŸ©é˜µä¹˜æ³•Kernel
- [ ] ç†è§£ï¼šä»€ä¹ˆæ˜¯Memory Boundï¼Ÿä»€ä¹ˆæ˜¯Compute Boundï¼Ÿ

---

**è®°ä½**ï¼šä¸è¦è¿½æ±‚å®Œç¾ï¼Œå…ˆè·‘é€šå†ä¼˜åŒ–ã€‚æ¯ä¸€æ­¥éƒ½è¦æœ‰è¾“å‡ºã€‚

**8ä¸ªæœˆåï¼Œä½ ä¼šæ„Ÿè°¢ç°åœ¨å¼€å§‹è¡ŒåŠ¨çš„è‡ªå·±ã€‚ğŸš€**

---

*æœ€åæ›´æ–°ï¼š2025-01-01*  
*é¡¹ç›®è¿›åº¦ï¼š0% â†’ ç›®æ ‡ï¼š100%*  
*å½“å‰Phaseï¼šå‡†å¤‡å¼€å§‹ â†’ ç›®æ ‡ï¼šPrincipal/Architectçº§*

