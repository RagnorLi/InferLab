// ==============================================================================
// Vector / Dynamic Array - 对应 LLM Inference 中的 KV Cache, Tensor
// ==============================================================================
//
// 【对应引擎模块】
//   - KV Cache: 存储每个 token 的 key/value 向量
//   - Tensor: 多维数组的底层存储
//
// 【学习重点】
//   1. 连续内存布局：所有元素在内存中连续存储，cache-friendly
//   2. 扩容机制：当容量不足时如何进行 2x 扩容（alloc -> realloc -> dealloc）
//   3. Stride (步长) 访问：模拟 Tensor 的多维访问模式
//
// 【实现要求】
//   - 实现 push, pop, get, resize 等核心操作
//   - 使用 std::alloc 手动管理内存（练习底层操作）
//   - 支持 stride 访问：给定起始位置和步长，返回指定元素
//   - 正确处理 Drop trait，避免内存泄漏
//
// 【练习目标】
//   - 理解 Rust 的所有权和生命周期在底层内存管理中的应用
//   - 掌握 unsafe 代码的正确使用方式
//   - 模拟 vLLM 中 KV Cache 的内存管理
// ==============================================================================
