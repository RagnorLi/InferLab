// ==============================================================================
// Heap (Priority Queue) - 对应 LLM Inference 中的 Scheduler (调度器)
// ==============================================================================
//
// 【对应引擎模块】
//   - Scheduler: 根据优先级调度推理请求
//   - Top-K Sampling: 采样阶段选择概率最高的 K 个 token
//
// 【学习重点】
//   1. 任务优先级排序：使用最小堆或最大堆维护待调度请求
//   2. Sift Down/Up 操作：堆的核心维护操作（O(log n)）
//   3. 堆的数组表示：父节点 i，左子 2i+1，右子 2i+2
//
// 【实现要求】
//   - 实现最小堆（Min Heap）：push, pop, peek, heapify
//   - 支持自定义比较器（用于实现最大堆）
//   - 实现 Top-K 算法：从数组中找出最大/最小的 K 个元素
//   - 测试在动态插入删除场景下的性能
//
// 【练习目标】
//   - 理解堆在调度系统中的核心作用
//   - 掌握 vLLM 中请求优先级调度的实现原理
//   - 熟悉 Top-K Sampling 中的堆优化技巧
// ==============================================================================

