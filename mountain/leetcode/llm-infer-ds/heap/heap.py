# ==============================================================================
# Heap (Priority Queue) - 对应 LLM Inference 中的 Scheduler (调度器)
# ==============================================================================
#
# 【对应引擎模块】
#   - Scheduler: 根据优先级调度推理请求
#   - Top-K Sampling: 采样阶段选择概率最高的 K 个 token
#
# 【学习重点】
#   1. 任务优先级排序：使用最小堆或最大堆维护待调度请求
#   2. Sift Down/Up 操作：堆的核心维护操作（O(log n)）
#   3. 堆的数组表示：父节点 i，左子 2i+1，右子 2i+2
#
# 【实现要求】
#   - 实现最小堆（Min Heap）：push, pop, peek, heapify
#   - 支持自定义比较函数（用于实现最大堆）
#   - 实现 Top-K 算法：从数组中找出最大/最小的 K 个元素
#   - 使用 list 作为底层存储
#
# 【练习目标】
#   - 理解堆在调度系统中的核心作用
#   - 掌握 vLLM 中请求优先级调度的实现原理
#   - 熟悉 Top-K Sampling 中的堆优化技巧
#
# 【提示】
#   - Python heapq 模块是最小堆，可以对比学习
#   - 最大堆可以通过取负数转换为最小堆
#   - 建议实现 _sift_up 和 _sift_down 私有方法
# ==============================================================================

